# hw0

## 1、大数据的含义是什么？

"大数据"是一个涵盖多种技术的概念，简单地说，是指无法在一定时间内用常规软件工具对其内容进行抓取、管理和处理的数据集合。大数据通常有如下特点：

1. **大量数据**：大数据通常包含大量的数据，数量可能远远超过传统数据存储和处理方法所能容纳的范围。这些数据可以来自各种来源，包括传感器、社交媒体、在线交易、日志文件等。

2. **多样性**：大数据涵盖了各种类型的数据，包括结构化数据（如数据库中的表格数据）、半结构化数据（如XML文件或JSON数据）、非结构化数据（如文本、图像和视频），以及时序数据、地理空间数据等。

3. **高速度**：大数据通常以非常快的速度生成，例如，社交媒体上的实时数据流、互联网交易日志等。这些数据需要在生成后尽快处理和分析，以获取有价值的信息。

4. **复杂性**：大数据集合通常具有复杂的内在关系和模式，这些关系可能不容易通过传统的数据处理方法来发现。

5. **价值潜力**：大数据中包含了有价值的信息，可以帮助组织做出更好的决策、发现趋势、改进产品和服务、优化运营等。

大数据的概念强调了处理、分析和利用这些庞大而多样化的数据集的挑战和机会。为了处理大数据，通常需要使用先进的数据存储、处理和分析技术，如分布式计算、云计算、机器学习和人工智能等。大数据分析可以用于许多领域，包括商业、医疗保健、金融、科学研究、政府和社交媒体等，以提取有价值的见解和知识。大数据已成为当今信息时代的一个重要趋势，对许多行业和领域产生了深远的影响。

---

## 2、大数据有哪些特征？

大数据具有以下主要特征，通常被称为"四个V"，即体积（Volume）、多样性（Variety）、速度（Velocity）和价值（Value），还有一个后来添加的特征，即可变性（Veracity）。

1. **体积（Volume）**：体积指的是大数据集合的规模之大。大数据通常包含比传统数据集合更多的数据，可以是几个TB、PB、甚至EB级别的数据量。这大大超出了传统数据库管理系统的容量限制。

2. **多样性（Variety）**：多样性表示大数据可以包含各种类型和格式的数据，包括结构化数据（如数据库表格）、半结构化数据（如XML或JSON）、非结构化数据（如文本、图像、音频和视频），以及时序数据、地理空间数据等。这种多样性增加了数据处理和分析的复杂性。

3. **速度（Velocity）**：速度强调了大数据的生成速率。大数据通常以高速度产生，例如，社交媒体上的实时数据流、传感器生成的数据、在线交易日志等。对这些数据的实时或近实时分析对许多应用至关重要。

4. **价值（Value）**：价值表示大数据中包含有价值的信息和见解，可以用于支持决策、发现趋势、改进产品和服务、优化业务等。挖掘大数据的价值是大数据分析的目标。

5. **可变性（Veracity）**：可变性强调了大数据的不确定性和质量问题。大数据集合中的数据质量可以因来源不同、数据收集方式、处理错误等因素而有所不同。处理不确定性和保证数据质量是大数据分析的重要挑战之一。

除了上述四个或五个主要特征外，还有一些其他特征，如复杂性（Complexity）、连通性（Connectivity）和实时性（Real-time），这些特征也可以用来描述大数据的性质。大数据的特征使得它们需要特殊的技术和工具来存储、处理、分析和提取价值。这些技术包括分布式计算、云计算、机器学习、人工智能和大数据分析平台等。

---

## 3、查询资料阐述大数据和人工智能之间的关系。

大数据（Big Data）和人工智能（Artificial Intelligence，AI）之间存在密切的关系，它们相互促进并共同推动了现代科技和商业的发展。以下是大数据和人工智能之间的关系：

1. **数据是AI的燃料**：数据是训练和优化AI算法的关键要素之一。机器学习和深度学习算法需要大量的数据来识别模式、进行训练和预测。大数据提供了足够的样本和信息，以便AI系统能够学习并改进其性能。

2. **数据驱动的洞察力**：大数据允许机器学习和AI系统从大规模数据中提取有价值的信息、趋势和见解。这些见解可以用于做出更好的决策、优化业务流程、改进产品和服务，以及发现新的商业机会。

3. **实时数据支持实时决策**：大数据处理技术允许实时或近实时地处理大量数据。这对于需要迅速响应变化的应用非常重要，如金融交易、在线广告投放、物联网设备的监控等。

4. **数据清洗和预处理**：大数据中可能包含噪音、缺失值和不一致的数据，这需要数据清洗和预处理。AI算法通常依赖于干净、准确的数据，因此大数据分析可以帮助准备和提供高质量的数据供AI使用。

5. **扩展AI的应用领域**：大数据和AI结合在一起，已经在许多应用领域取得了突破性的进展，包括自动驾驶汽车、医疗诊断、自然语言处理、图像识别、预测分析等。这些应用依赖于大数据的收集和AI的分析来实现。

6. **AI优化数据管理**：人工智能技术可以用于优化大数据的存储、查询和管理。例如，AI可以自动化数据分类、标记、分析和检索过程，使数据管理更高效。

总的来说，大数据提供了支持人工智能应用所需的丰富、多样和大规模的数据资源。同时，人工智能技术能够从大数据中提取有价值的信息和洞察力，使其更具实际应用价值。因此，大数据和人工智能之间的协同作用已经成为当今科技和商业领域的关键推动力之一，它们相辅相成，共同推动着科学研究、商业决策和技术创新的发展。

---

## 4、查询资料，阐述大数据开源项目Hadoop、Spark、Hive和HBase各自的作用。

Hadoop、Spark、Hive 和 HBase 都是与大数据处理和分析相关的开源项目，它们各自具有不同的作用和特点。以下是它们的主要作用：

1. **Hadoop**：
   - **作用**：Hadoop是一个分布式计算框架，旨在处理大规模数据集的存储和处理。它的核心是Hadoop分布式文件系统（HDFS）和MapReduce编程模型。
   - **特点**：
     - 存储：HDFS用于将数据分布式存储在多台服务器上，提供容错性和高可用性。
     - 处理：MapReduce用于分布式批处理，允许用户编写Map和Reduce任务来处理数据。
     - 适用于：适用于离线数据处理，对于需要高容错性和可扩展性的任务非常有用。

2. **Spark**：
   - **作用**：Spark是一个高性能、通用性强的分布式计算框架，用于批处理、流处理、机器学习等多种数据处理任务。
   - **特点**：
     - 进程内计算：相对于Hadoop的磁盘IO，Spark在内存中进行数据处理，因此速度更快。
     - 多语言支持：支持多种编程语言，包括Scala、Java、Python和R。
     - 适用于：适用于复杂的数据处理、机器学习和图计算等多种应用。

3. **Hive**：
   - **作用**：Hive是一个基于Hadoop的数据仓库工具，它提供了一种SQL-like查询语言（HiveQL），使用户能够轻松地查询和分析存储在Hadoop中的数据。
   - **特点**：
     - SQL界面：允许非技术用户使用SQL查询大数据。
     - 元数据存储：Hive使用元数据来描述数据结构和存储位置。
     - 适用于：适用于数据分析、报告生成和数据挖掘等任务。

4. **HBase**：
   - **作用**：HBase是一个分布式NoSQL数据库，专为大规模数据集设计，具有高可扩展性和实时读写能力。
   - **特点**：
     - 列族：数据以列族的形式存储，支持宽表设计。
     - 实时读写：适用于需要快速访问和实时查询的应用。
     - 适用于：适用于需要快速随机访问大量数据的应用，如社交媒体、日志分析等。

这些开源项目在大数据生态系统中发挥不同的作用，可以根据具体的需求和应用场景选择使用它们中的一个或多个。大数据处理通常涉及到数据存储、批处理、流处理、查询和分析，这些工具可以协同工作，构建强大的大数据解决方案。例如，可以使用Hadoop和Hive来存储和查询数据，使用Spark来进行批处理和流处理，同时使用HBase来支持实时访问和查询。

---

# hw1

## （1）单机模式、伪分布式模式和完全分布式模式有何区别？

1. 单机模式（Standalone Mode）：
   - 单机模式是Hadoop的最简单模式，用于开发和调试目的。
   - 在单机模式下，Hadoop不会启动分布式处理集群，而是在单台计算机上运行所有组件。
   - 数据通常存储在本地文件系统中，而不是Hadoop分布式文件系统（HDFS）中。
   - 适用于小规模数据处理，不具备分布式计算的优势。

2. 伪分布式模式（Pseudo-Distributed Mode）：
   - 伪分布式模式模拟了一个完全分布式的Hadoop集群，但实际上只在一台计算机上运行所有组件。
   - Hadoop各组件（如NameNode、DataNode、ResourceManager、NodeManager等）都在单台计算机上运行，但它们之间仍然以分布式方式通信。
   - 数据通常存储在HDFS中，模拟了真实分布式环境。
   - 适用于开发和测试，用于验证Hadoop作业的正确性。

3. 完全分布式模式（Fully-Distributed Mode）：
   - 完全分布式模式是Hadoop在真实分布式集群上运行的模式。
   - 在完全分布式模式下，Hadoop集群由多台计算机组成，每台计算机都可以扮演不同的角色，如NameNode、DataNode、ResourceManager、NodeManager等。
   - 数据存储在HDFS中，通过多台计算机共同管理和处理。
   - 完全分布式模式适用于大规模数据处理，可以充分发挥Hadoop的分布式计算能力，提高性能和容错性。

---

## （2）为什么要配置ssh免密登录？

配置SSH免密登录是为了提高系统管理和远程操作的便利性和安全性。以下是配置SSH免密登录的主要原因：

1. 简化远程登录流程：SSH免密登录允许用户在不需要每次都输入密码的情况下远程登录到目标服务器。这样，管理员和开发人员可以更快速地访问和管理远程服务器，减少了登录的复杂性。

2. 自动化脚本和任务：SSH免密登录对于自动化脚本和任务非常重要。管理员可以编写脚本来自动执行各种系统管理任务，如备份、监控、部署和配置管理，而无需手动输入密码。这提高了系统管理的效率和一致性。

3. 批量操作：在服务器集群或多台服务器上执行批量操作时，SSH免密登录非常有用。管理员可以轻松地批量执行命令、上传或下载文件，而无需为每台服务器输入密码。

4. 安全性：尽管SSH免密登录似乎降低了安全性，但实际上可以通过正确的配置来提高安全性。使用SSH密钥对（公钥和私钥）可以实现身份验证，而不是仅依赖密码。私钥通常存储在客户端，而公钥存储在服务器上。这种方式使得攻击者难以通过猜测密码来登录服务器。

5. 避免密码暴露：在配置SSH免密登录之前，通常需要输入密码进行身份验证。如果密码是明文传输或存储在不安全的地方，那么可能会被恶意攻击者获取。SSH免密登录通过使用密钥对来替代密码，减少了密码泄漏的风险。

---

## （3）/etc/hostname和/etc/hosts的作用分别是什么？

1. `/etc/hostname` 文件：
   - `/etc/hostname` 文件通常包含本地主机的主机名（hostname）信息。
   - 主机名是系统标识自己的名称，通常用于网络通信和标识主机。在Hadoop集群中，每个节点都应该有唯一的主机名，以便其他节点可以识别和联系它。
   - Hadoop集群的各个节点（包括主节点和从节点）需要知道它们自己的主机名以及其他节点的主机名，以便进行通信和协调工作。因此，在Hadoop配置中，通常需要确保每个节点的 `/etc/hostname` 文件包含正确的主机名。

2. `/etc/hosts` 文件：
   - `/etc/hosts` 文件是用于本地主机名解析的文件，通常包含主机名与IP地址的映射关系。
   - 在Hadoop集群中，每个节点都应该能够识别其他节点的主机名，并将它们解析为相应的IP地址，以便建立网络连接和进行通信。
   - `/etc/hosts` 文件可以用来手动配置主机名与IP地址的映射，以确保节点之间可以正确地解析彼此的主机名。这对于Hadoop的节点之间的通信非常重要，因为Hadoop组件（如NameNode、DataNode、ResourceManager、NodeManager等）在通信时通常使用主机名而不是IP地址。

---

## （4）Hadoop的四个主要xml配置文件是哪四个，分别用于配置什么参数？

Hadoop的四个主要XML配置文件是：

1. **core-site.xml**：
   - 用于配置Hadoop核心参数，如文件系统相关的设置、Hadoop日志和通用设置。
   - 一些常见的参数包括：
     - `fs.defaultFS`：指定Hadoop文件系统的默认URI。
     - `hadoop.tmp.dir`：指定Hadoop临时文件的存储路径。
     - `io.file.buffer.size`：指定文件系统读写缓冲区的大小。
     - `hadoop.proxyuser.username.hosts`和`hadoop.proxyuser.username.groups`：用于配置代理用户访问权限。
2. **hdfs-site.xml**：
   - 用于配置Hadoop分布式文件系统（HDFS）的参数。
   - 一些常见的参数包括：
     - `dfs.replication`：指定HDFS块的副本数。
     - `dfs.namenode.name.dir`和`dfs.datanode.data.dir`：分别指定NameNode和DataNode的存储目录。
     - `dfs.permissions.enabled`：启用或禁用HDFS权限。
     - `dfs.blocksize`：指定HDFS块的大小。
3. **mapred-site.xml**：
   - 用于配置Hadoop MapReduce（分布式计算框架）的参数。
   - 一些常见的参数包括：
     - `mapreduce.framework.name`：指定MapReduce框架的名称（本地模式、YARN等）。
     - `mapreduce.jobtracker.address`：指定JobTracker的主机和端口。
     - `mapreduce.tasktracker.http.address`：指定TaskTracker的HTTP访问地址。
4. **yarn-site.xml**：
   - 用于配置Hadoop的资源管理和任务调度框架YARN（Yet Another Resource Negotiator）的参数。
   - 一些常见的参数包括：
     - `yarn.resourcemanager.hostname`：指定ResourceManager的主机名。
     - `yarn.nodemanager.local-dirs`和`yarn.nodemanager.log-dirs`：分别指定NodeManager的本地目录和日志目录。
     - `yarn.log-aggregation-enable`：启用或禁用YARN日志聚合功能。
     - `yarn.scheduler.maximum-allocation-mb`：指定YARN中单个容器的最大内存分配。

---

# hw2

## 1、列出HDFS中根目录下的文件和子目录；

### hdfs dfs -ls /

## 2、在HDFS根目录中新建文件夹abc；

### hdfs dfs -mkdir /abc

## 3、将本地目录中的test.txt文件上传到上述abc目录中；

### hdfs dfs -put test.txt /abc

## 4、从HDFS下载/abc/test.txt到本地并改名为abc.txt；

### hdfs dfs -get /abc/test.txt abc.txt

## 5、删除HDFS中的/abc/test.txt文件；

### hdfs dfs -rm -r /abc/test.txt

## 6、删除HDFS中的/abc目录；

### hdfs dfs -rm -r -f /abc

---

# hw3

**统计user_login.txt文件中用户在2016年登录的总次数**

数据集：

[![157396896626242542e5a59bd41eaf3e.png](https://s1.imagehub.cc/images/2023/11/28/157396896626242542e5a59bd41eaf3e.png)](https://www.imagehub.cc/image/14esW4)

https://github.com/ChengZ2003/learnHadoop/tree/main/loginCount

# hw4

**编写MapReduce程序计算成绩最高分和平均分**

数据集：
[![3f358ddd4f873eb32b3abe49c239aacf.png](https://s1.imagehub.cc/images/2023/11/28/3f358ddd4f873eb32b3abe49c239aacf.png)](https://www.imagehub.cc/image/14ecdT)


https://github.com/ChengZ2003/learnHadoop/tree/main/maxAndAverageScore

# hw5

**按月统计user_login.txt文件中各个用户登录的总次数**

https://github.com/ChengZ2003/learnHadoop/tree/main/loginPerMonthCountv1

https://github.com/ChengZ2003/learnHadoop/tree/main/loginPerMonthCountv2

数据集见**hw3**

---

# hw6

**根据student.txt数据集统计学生成绩**，要求：

（1）创建自定类型，描述student.txt中各项内容；

‍（2）利用自定义类型，求各个同学平均分（浮点类型）；

‍（3）输出按照平均分进行排序（从高到底）；

（4）‍如果有平均分相同的，按照学号进行排序；

（5）将两个班的成绩统计结果分别存储到两个文件中；

（6）‍提交实验报告，包括java文件和student.txt,以及部分结果

数据集：
[![60790f57a9155704317c679d4b3043f9.png](https://s1.imagehub.cc/images/2023/11/28/60790f57a9155704317c679d4b3043f9.png)](https://www.imagehub.cc/image/14eHLd)


https://github.com/ChengZ2003/learnHadoop/tree/main/studentScore

---

